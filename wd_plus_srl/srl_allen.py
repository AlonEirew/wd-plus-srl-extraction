import argparse
import json
import os

from allennlp.predictors.predictor import Predictor

from wd_plus_srl.data import io
from wd_plus_srl.data.data_loader import EcbDataLoader, IDataLoader
from wd_plus_srl.data.doc import Doc
from wd_plus_srl.data.io import json_serialize_default
from wd_plus_srl.data.sentence import SRLSentence, SRLVerb, SRLArg


def run_srl(ecb_path: str, data_loader: IDataLoader):
    documents = data_loader.read_data_from_corpus_folder(ecb_path)
    predictor = Predictor.from_path(
        "https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz")

    sentences = Doc.to_sentences(documents)
    all_sentence_verbs = list()
    for sentence in sentences:
        srl_sentence = SRLSentence(sentence.doc_id, sentence.sent_id)
        sentence_word = sentence.get_sentence_words()
        prediction = predictor.predict_tokenized(tokenized_sentence=sentence_word)
        verbs = prediction['verbs']
        words = prediction['words']
        for verb in verbs:
            srl_verb = SRLVerb()
            tags = verb['tags']
            srl_verb.add_var(tags, words)
            srl_sentence.add_srl_vrb(srl_verb)

        all_sentence_verbs.append(srl_sentence)
        print('Dont with sentence from doc-' + sentence.doc_id + ', withId-' + str(sentence.sent_id))

    return all_sentence_verbs


def read_srl_json(file_path):
    '''
    Use this method to generate back an object from the json output file
    :param file_path: the json file generated by 'run_srl' method
    :return: return all document sentences list of SRL objects
    '''
    with open(file_path) as f:
        data = json.load(f)

    all_doc_sentences = list()
    for data_obj in data:
        doc_id = data_obj['ecb_doc_id'] #str
        sent_id = data_obj['ecb_sent_id'] #int
        srl_obj = data_obj['srl'] #list

        srl_sentences = SRLSentence(doc_id, sent_id)
        for obj in srl_obj:
            srl_verb_obj = SRLVerb()
            if 'verb' in obj and obj['verb'] is not None:
                verb = obj['verb']
                srl_verb_obj.verb = SRLArg(verb['text'], verb['ecb_tok_ids'])
            if 'arg0' in obj and obj['arg0'] is not None:
                arg0 = obj['arg0']
                srl_verb_obj.arg0 = SRLArg(arg0['text'], arg0['ecb_tok_ids'])
            if 'arg1' in obj and obj['arg1'] is not None:
                arg1 = obj['arg1']
                srl_verb_obj.arg1 = SRLArg(arg1['text'], arg1['ecb_tok_ids'])
            if 'arg_tmp' in obj and obj['arg_tmp'] is not None:
                arg_tmp = obj['arg_tmp']
                srl_verb_obj.arg_tmp = SRLArg(arg_tmp['text'], arg_tmp['ecb_tok_ids'])
            if 'arg_loc' in obj and obj['arg_loc'] is not None:
                arg_loc = obj['arg_loc']
                srl_verb_obj.arg_loc = SRLArg(arg_loc['text'], arg_loc['ecb_tok_ids'])
            if 'arg_neg' in obj and obj['arg_neg'] is not None:
                arg_neg = obj['arg_neg']
                srl_verb_obj.arg_neg = SRLArg(arg_neg['text'], arg_neg['ecb_tok_ids'])

            srl_sentences.add_srl_vrb(srl_verb_obj)

        all_doc_sentences.append(srl_sentences)

    return all_doc_sentences


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Create SRL for ECB+ by AllenNLP')
    parser.add_argument('--ecb_root_path', type=str, help='corpus root', required=True)
    parser.add_argument('--output_file', type=str, help='output file', required=True)

    args = parser.parse_args()
    io.create_if_not_exist(os.path.dirname(args.output_file))

    ecb_data_loader = EcbDataLoader()
    srl_result = run_srl(args.ecb_root_path, ecb_data_loader)

    with open(args.output_file, 'w') as f:
        json.dump(srl_result, f, default=json_serialize_default, indent=4, sort_keys=True)

    # read_srl_json('output/allen_srl.json')
